{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def _dtw(output, target, window):\n",
    "    n, m = len(output), len(target)\n",
    "    w = np.max([window, abs(n-m)])\n",
    "    dtw_matrix = np.zeros((n+1, m+1))\n",
    "    dtw_matrix += float(\"Inf\")\n",
    "    dtw_matrix[0, 0] = 0\n",
    "    for i in range(1, n+1):\n",
    "        a, b = np.max([1, i-w]), np.min([m, i+w])+1\n",
    "        dtw_matrix[i,a:b] = 0\n",
    "        \n",
    "        \n",
    "        for j in range(a, b):\n",
    "            cost = np.abs(output[i-1] - target[j-1])\n",
    "            last_min = np.min([dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1]])\n",
    "            dtw_matrix[i, j] = cost + last_min\n",
    "            \n",
    "    return dtw_matrix[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"kernel\": ['rbf','linear','poly'],\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"gamma\":[0.0001,0.001,0.01],\n",
    "    \"degree\":[1,2,3]\n",
    "}\n",
    "svr = SVR()\n",
    "gssvr = GridSearchCV(svr, params, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "#pipe2 = Pipeline([('poly2', PolynomialFeatures(2)), ('linReg', lr)])\n",
    "#pipe3 = Pipeline([('poly3', PolynomialFeatures(3)), ('linReg', lr)])\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "params = {\n",
    "    \"n_estimators\": [50,100,500]\n",
    "    \n",
    "}\n",
    "rfg = RandomForestRegressor()\n",
    "gsrfg = GridSearchCV(rfg, params, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "params = {\n",
    "    \"n_iter\": [100,1000,2000],\n",
    "    \"tol\": [1e-6, 1e-8, 1e-10]\n",
    "}\n",
    "br = BayesianRidge()\n",
    "gsbr= GridSearchCV(br, params, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "params = {\n",
    "    \"n_neighbors\": [50, 100, 300, 1000],\n",
    "    \"weights\": ['uniform','distance'],\n",
    "    \"algorithm\": ['ball_tree', 'kd_tree', 'brute']\n",
    "    \n",
    "}\n",
    "knn = KNeighborsRegressor()\n",
    "gsknn = GridSearchCV(knn, params, scoring = 'neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Linear Regression\": lr,\n",
    "    \"Bayesian Ridge Regression\": gsbr,\n",
    "    \"Support Vector Regression\": gssvr,\n",
    "    \"Random Forest Regression\": gsrfg,\n",
    "    \"KNN-Regression\": gsknn\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EURGBP\n",
      "KNN-Regression\n",
      "{'weights': 'distance', 'algorithm': 'ball_tree', 'n_neighbors': 50}\n",
      "2.0092355622018077\n",
      "Random Forest Regression\n"
     ]
    }
   ],
   "source": [
    "from Scripts.utils import *  \n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Scripts.FastDTW import *\n",
    "\n",
    "columns = ['Date','Open','High','Low','Close','Volume','Yield','PercentageVolume',\n",
    "           'SMA6','EMA6','WMA6','HMA6','SMA20','EMA20','WMA20','HMA20','SMA50','EMA50','WMA50','HMA50',\n",
    "           'SMA100','EMA100','WMA100','HMA100','MACD','CCI','Stochastic Oscillator','RSI','ROC','PPO',\n",
    "           'KST','BOLU','BOLD','BOLM']\n",
    "\n",
    "for pair in os.listdir('DataReady'):\n",
    "    if pair in ['EURUSD','EURGBP','EURCAD','EURAUD','EURJPY','EURCHF','USDJPY','USDCAD','AUDCAD','GBPUSD','AUDUSD']:\n",
    "        print(pair)\n",
    "        data = pd.read_csv('DataReady/{}/{}_H4.csv'.format(pair, pair), names = columns, header = 0)\n",
    "        #data = data[:-23000]\n",
    "        toRemove = ['Volume', 'Date','High','Low','Open','Close']\n",
    "        df = selectData(data,toRemove)\n",
    "        closingPrices = data['Close']\n",
    "        closingPrices = closingPrices.reset_index(drop=True)\n",
    "        normDf = normalizeData(df)\n",
    "        images = generateImages(normDf)\n",
    "        images = np.array(images)\n",
    "\n",
    "        train_X, _, train_Y, _ = train_test_split(images, closingPrices[28:], test_size = 0.2,shuffle = True, random_state = 42)\n",
    "        _, test_X, _, test_Y = train_test_split(images, closingPrices[28:], test_size = 0.2,shuffle = False)\n",
    "        train_X, test_X = train_X.reshape(train_X.shape[0],28*28).astype(np.float32), test_X.reshape(test_X.shape[0],28*28).astype(np.float32)\n",
    "        \n",
    "        for clf in classifiers.keys():\n",
    "            print(clf)\n",
    "            test_hat_Y = classifiers[clf].fit(train_X, train_Y).predict(test_X)\n",
    "            best_param = 0\n",
    "            try:\n",
    "                best_param = classifiers[clf].best_params_\n",
    "                print(best_param)\n",
    "            except:\n",
    "                print(0)\n",
    "                \n",
    "            mse = np.mean((test_hat_Y-test_Y)**2)\n",
    "            corr = np.corrcoef(test_hat_Y, test_Y)[0,1]\n",
    "            dti = _dtw(np.array(test_hat_Y), np.array(test_Y), 1)\n",
    "            fast_dti = fastdtw(test_hat_Y, test_Y, 1)[0]\n",
    "            print(fast_dti)\n",
    "            \n",
    "            with open(\"Results/ResultsML.txt\",\"a+\") as f:\n",
    "                f.write(\"{}_H4,{},{},{},{},{},{}\\n\".format(pair, clf, mse, corr, dti, fast_dti, best_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EURCAD\n",
      "Linear Regression\n",
      "KNN Regression\n",
      "Support Vector Regression\n",
      "Bayesian Ridge Regression\n",
      "Random Forest Regression\n",
      "GBPUSD\n",
      "Linear Regression\n",
      "KNN Regression\n",
      "Support Vector Regression\n",
      "Bayesian Ridge Regression\n",
      "Random Forest Regression\n",
      "EURCHF\n",
      "Linear Regression\n",
      "KNN Regression\n",
      "Support Vector Regression\n",
      "Bayesian Ridge Regression\n",
      "Random Forest Regression\n",
      "EURJPY\n",
      "Linear Regression\n",
      "KNN Regression\n",
      "Support Vector Regression\n",
      "Bayesian Ridge Regression\n",
      "Random Forest Regression\n",
      "EURAUD\n",
      "Linear Regression\n",
      "KNN Regression\n",
      "Support Vector Regression\n",
      "Bayesian Ridge Regression\n",
      "Random Forest Regression\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Scripts.utils import *\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "classifiers = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Bayesian Ridge Regression\": BayesianRidge(),\n",
    "    \"Support Vector Regression\": SVR(),\n",
    "    \"Random Forest Regression\": RandomForestRegressor(),\n",
    "    \"KNN Regression\": KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "columns = ['Date','Open','High','Low','Close','Volume','Yield','PercentageVolume',\n",
    "           'SMA6','EMA6','WMA6','HMA6','SMA20','EMA20','WMA20','HMA20','SMA50','EMA50','WMA50','HMA50',\n",
    "           'SMA100','EMA100','WMA100','HMA100','MACD','CCI','Stochastic Oscillator','RSI','ROC','PPO',\n",
    "           'KST','BOLU','BOLD','BOLM']\n",
    "\n",
    "with open(\"Models/MLModels.json\",\"r\") as f:\n",
    "    models = json.load(f)\n",
    "for pair in os.listdir('DataReady'):\n",
    "    if len(pair)==6 and pair not in ['EURGBP','USDJPY','AUDUSD','AUDCAD','EURUSD','USDCAD','EURCAD','GBPUSD','EURCHF']:\n",
    "        print(pair)\n",
    "        data = pd.read_csv('DataReady/{}/{}_D1.csv'.format(pair, pair), names = columns, header = 0)\n",
    "        toRemove = ['Volume', 'Date','High','Low','Open','Close']\n",
    "        df = selectData(data,toRemove)\n",
    "        closingPrices = data['Close']\n",
    "        closingPrices = closingPrices.reset_index(drop=True)\n",
    "        normDf = normalizeData(df)\n",
    "        images = generateImages(normDf)\n",
    "        images = np.array(images)\n",
    "\n",
    "        train_X, _, train_Y, _ = train_test_split(images, closingPrices[28:], test_size = 0.2,shuffle = True, random_state = 42)\n",
    "        train_X = train_X.reshape(train_X.shape[0],28*28).astype(np.float32)\n",
    "        \n",
    "        for clf in classifiers.keys():\n",
    "            print(clf)\n",
    "            model = classifiers[clf].set_params(**models[clf][pair])\n",
    "            model.fit(train_X, train_Y)\n",
    "            # save the model to disk\n",
    "            filename = 'Models/{}_{}.sav'.format(clf.replace(\" \",\"\"),pair)\n",
    "            pickle.dump(model, open(filename, 'wb'))\n",
    "            #loaded_model = pickle.load(open(filename, 'rb'))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
